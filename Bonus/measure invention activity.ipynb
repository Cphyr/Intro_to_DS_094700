{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Project \"Meditest×´</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to COVID-19 there is a high demand for identifying at-risk population to provide necessary aid. For this purpose, \"Meditest\" company recruited two teams to build classifiers for at-risk population. Each of these teams suggeted a classifier that was trained on data gathered from thousands of people including medical information such as pre-existing condition, blood pressure and pulse. For each given person, the classifier predicts whether he belongs to in-risk population or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the classifiers and choose the better one, \"Meditest\" company assembled real classification data on a group of 40 people in which it is known if they belong to at-risk population or not. This group of people was not included in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real data is presented below:<br>0 - Does not belong to at-risk population<br>1 - Belongs to at-risk population "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=100) # for printing each array in a single line\n",
    "\n",
    "# The real_data Numpy array contains 40 items representing the real data gathered by \"Meditest\".\n",
    "# Each item in the Numpy array represents the true and reliable classification of a person. \n",
    "# 0 - does not belong to at risk population, 1 - belongs to at risk population.\n",
    "# For example, the person in index 0 is not at risk, while the last one (index 39) is at risk\n",
    "\n",
    "real_data    = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
    "                         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The company's management team asks your help in choosing the most suitable classifier among the following suggested classifiers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each item in each of the following Numpy arrays represents the predicted classification of a person. \n",
    "\n",
    "classifier_1 = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
    "                         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1])\n",
    "classifier_2 = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
    "                         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the classifiers will you recommend - classifier_1 or classifier_2? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< Write your answer here - no need for code, but you can use code if it helps in choosing a classifier >\n",
    "\n",
    "I think the second classifier is better, because, it succeeded in predicting the people at risk. \n",
    "On the other hand, it did classified some non-risk as risk, but, predicting the people at risk right, is much important than predicting some false positive, becuase those of the false positive group, will just be checked.\n",
    "Hence, the second classifier is more cost-effective.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each item in each of the following Numpy arrays represents the predicted classification of a person. \n",
    "\n",
    "classifier_3 = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
    "                         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0])\n",
    "classifier_4 = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
    "                         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the classifiers will you recommend - classifier_3 or classifier_4? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< Write your answer here - no need for code, but you can use code if it helps in choosing a classifier >\n",
    "\n",
    "The 3rd classifier doesn't predict, not even one, of the at-risk people.\n",
    "The 4th classifier got low accuracy, but it predicts the truly-at-risk right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggest a numeric measure to estimate how good a classifier is. Higher number indicates a better classifier. Describe the measure in words, how would you calculate it?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< Write your answer here >\n",
    "\n",
    "We'd emphasize more on a low false-negative.\n",
    "Recall - what precentange of the true-at-risk people, the model classified as at-risk.\n",
    "Hence, we'd recommend recall as the numeric measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement your suggested measure. The measure gets two Numpy arrays as input; The first represents the real data, and the second represents the classifier's estimation. The measure should return a score (number) to indicate how good the classifier is. A higher score indicates a better classifier.\n",
    "\n",
    "You can use the attached example of a measure you already fimiliar with - the accuracy score. It just calculates the proportion of the correct estimations of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: write your code in the provided code cells and **do not** change the signature of the method. That is, do not change the names of the methods (e.g., calculate_measure) or the input parameters (real_data, classifier_results). Delete the 'pass' keyword and fill your code instead.\n",
    "\n",
    "**Notice**: There is more than one possible solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier measurement example - accuracy\n",
    "def calculate_accuracy(real_data, classifier_results):\n",
    "    correct = 0\n",
    "    for person_index in range(len(real_data)):\n",
    "        if real_data[person_index] == classifier_results[person_index]:\n",
    "            correct += 1\n",
    "    \n",
    "    success_rate = correct / len(real_data)\n",
    "    return success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_measure(real_data, classifier_results):\n",
    "    denom = sum(real_data) #count of the positives.\n",
    "\n",
    "    # calc the count of true-positives\n",
    "    nom = sum([x == 1 and y == 1 for x,y in zip(real_data,classifier_results)])\n",
    "\n",
    "    return nom / denom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your measure on the classifiers provided earlier. Does your measure score supports your choices in task 1a and task 1b?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5\n1.0\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "print(calculate_measure(real_data, classifier_1))\n",
    "print(calculate_measure(real_data, classifier_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please submit your notebook in the following link: <a href=\"http://3.128.181.72\">Invention activities submission framework</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python378jvsc74a57bd0fc18a244dbcdc6696b70199265f9844bcc7723b686192f18eb46cc84bc977650",
   "display_name": "Python 3.7.8 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "fc18a244dbcdc6696b70199265f9844bcc7723b686192f18eb46cc84bc977650"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}